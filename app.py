import streamlit as st
import openai
import json
import os
import sys
import pandas as pd
import numpy as np

# [ì¶”ê°€] Streamlit ìºì‹œ ì‚¬ìš©ì„ ìœ„í•´ ì„í¬íŠ¸
from streamlit.runtime.caching import cache_data, cache_resource

# sqlite3 ëŒ€ì‹  pysqlite3 ì‚¬ìš©
try:
    import pysqlite3
    sys.modules["sqlite3"] = sys.modules.pop("pysqlite3")  # ê¸°ì¡´ sqlite3 ëŒ€ì‹  pysqlite3 ì‚¬ìš©
except Exception as e:
    st.warning(f"âš ï¸ sqlite3 ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

import chromadb
from chromadb.config import Settings
from FlagEmbedding import BGEM3FlagModel
import torch
import time
from transformers import AutoModel

############################
# 0) GPT API Key
############################
openai.api_key = st.secrets["OPENAI_API_KEY"]
client = openai.OpenAI(api_key=openai.api_key)

############################
# ë“¤ì—¬ì“°ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°í˜¸ ëª©ë¡ (ìµœìƒë‹¨ì—ë§Œ ì¡´ì¬)
############################
INDENTATION_MARKERS = [
    "1)", "2)", "3)", "4)", "5)", "6)", "7)", "8)", "9)", "10)", "-", "[",
    "1. ", "2. ", "3. ", "4. ", "5. ", "6. ", "7. ", "8. ", "9.", "10. ",
    "â– ", "â—", "ã†", "Â·", "â€¢", "ã…‡", "â€œ", "â€˜", "[1]", "[2]", "[3]", "[4]", "[5]", "[6]", "[7]", "[8]", "[9]", "[10]",
    "(1)", "(2)", "(3)", "(4)", "(5)", "(6)", "(7)", "(8)", "(9)", "(10)", "â—‹", "â–ª", "â–¶", "â€¢", "ã€"
]

############################
# ê³µí†µ ìœ í‹¸ í•¨ìˆ˜ (apply_indentation, display_partial_text)
############################
def apply_indentation(text):
    lines = text.split('\n')
    indented_lines = []
    for line in lines:
        if any(line.strip().startswith(marker) for marker in INDENTATION_MARKERS):
            indented_lines.append(f"    {line.strip()}")
        else:
            indented_lines.append(line)
    return '\n'.join(indented_lines)

def display_partial_text(label: str, text: str, char_limit=100):
    """
    label: ì„¹ì…˜ ë¼ë²¨ (ì˜ˆ: 'ì£¼ìš” ì—…ë¬´', 'ìê²© ìš”ê±´' ë“±)
    text: ì‹¤ì œ í…ìŠ¤íŠ¸
    char_limit: ë¯¸ë¦¬ë³´ê¸° ê¸¸ì´ ì œí•œ
    """
    if not text or pd.isna(text):
        st.markdown(f"**{label}:** ë‚´ìš©ì´ ê²Œì‹œë˜ì–´ ìˆì§€ ì•Šì•„ìš”!")
        return

    text = apply_indentation(text)
    if len(text) <= char_limit:
        st.markdown(f"**{label}:**")
        st.text(text)
    else:
        truncated = text[:char_limit] + "..."
        st.markdown(f"**{label}:**")
        st.text(truncated)
        with st.expander("ìƒì„¸ ë³´ê¸°"):
            st.text(text)

############################
# [ì¶”ê°€] ì—‘ì…€ íŒŒì¼ ìºì‹± ë¡œë“œ
############################
@cache_data(show_spinner=False)
def load_all_excel_data(path:str = "./all_raw.xlsx") -> pd.DataFrame:
    """
    all_raw.xlsx ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ë¡œë“œ í›„ ìºì‹±
    ì—¬ëŸ¬ ì‚¬ìš©ìê°€ ë™ì‹œì— ì ‘ê·¼í•´ë„ íŒŒì¼ì„ ì¤‘ë³µë¡œë“œí•˜ì§€ ì•Šë„ë¡ í•¨
    """
    df = pd.read_excel(path)
    df["ê³µê³ id"] = df["ê³µê³ id"].astype(str)
    return df

############################
# [ì¶”ê°€] BGE ëª¨ë¸ ìºì‹±
############################
@cache_resource(show_spinner=False)
def get_bge_model():
    """
    BGE ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ëª¨ë“  ì„¸ì…˜(ì‚¬ìš©ì)ì´ ê³µìœ í•˜ë„ë¡ í•¨
    """
    # ë¡œê·¸ ì¶œë ¥ë¬¸ ì œê±°
    model = BGEM3FlagModel(
        'BAAI/bge-m3',
        use_fp16=False,  # CPUë¼ë©´ False
        device="cpu"
    )
    return model

############################
# [ì¶”ê°€] ChromaDB ì»¬ë ‰ì…˜ ìºì‹±
############################
@cache_resource(show_spinner=False)
def get_chroma_collection(db_path: str = "./chroma_db_bge", collection_name: str = "job_postings_collection"):
    """
    chroma_dbë¥¼ í•œ ë²ˆë§Œ ìƒì„±í•˜ì—¬ ëª¨ë“  ì„¸ì…˜ì´ ê³µìœ .
    ì½ê¸° ì „ìš©ìœ¼ë¡œ ì‚¬ìš© ì‹œ ë™ì‹œ ì ‘ê·¼ ë¬¸ì œê°€ ì¤„ì–´ë“¦.
    """
    # ë¡œê·¸ ì¶œë ¥ë¬¸ ì œê±°
    client_chroma = chromadb.PersistentClient(path=db_path)
    collection = client_chroma.get_collection(collection_name)
    return collection

############################
# 1) ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
############################
if "selected_tab" not in st.session_state:
    st.session_state["selected_tab"] = "job_recommendation"

if "selected_sido" not in st.session_state:
    st.session_state["selected_sido"] = []

############################
# 2) í•œêµ­ ì‹œë„/ì‹œêµ°êµ¬ ë°ì´í„°
############################
location_dict = {
    "ì„œìš¸": ["ì¢…ë¡œêµ¬", "ì¤‘êµ¬", "ìš©ì‚°êµ¬", "ì„±ë™êµ¬", "ê´‘ì§„êµ¬", "ë™ëŒ€ë¬¸êµ¬", "ì¤‘ë‘êµ¬", "ì„±ë¶êµ¬",
             "ê°•ë¶êµ¬", "ë„ë´‰êµ¬", "ë…¸ì›êµ¬", "ì€í‰êµ¬", "ì„œëŒ€ë¬¸êµ¬", "ë§ˆí¬êµ¬", "ì–‘ì²œêµ¬",
             "ê°•ì„œêµ¬", "êµ¬ë¡œêµ¬", "ê¸ˆì²œêµ¬", "ì˜ë“±í¬êµ¬", "ë™ì‘êµ¬", "ê´€ì•…êµ¬", "ì„œì´ˆêµ¬",
             "ê°•ë‚¨êµ¬", "ì†¡íŒŒêµ¬", "ê°•ë™êµ¬"],
    "ë¶€ì‚°": ["ì¤‘êµ¬", "ì„œêµ¬", "ë™êµ¬", "ì˜ë„êµ¬", "ë¶€ì‚°ì§„êµ¬", "ë™ë˜êµ¬", "ë‚¨êµ¬", "ë¶êµ¬",
             "í•´ìš´ëŒ€êµ¬", "ì‚¬í•˜êµ¬", "ê¸ˆì •êµ¬", "ê°•ì„œêµ¬", "ì—°ì œêµ¬", "ìˆ˜ì˜êµ¬", "ì‚¬ìƒêµ¬",
             "ê¸°ì¥êµ°"],
    "ëŒ€êµ¬": ["ì¤‘êµ¬", "ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ìˆ˜ì„±êµ¬", "ë‹¬ì„œêµ¬", "ë‹¬ì„±êµ°", "êµ°ìœ„êµ°"],
    "ì¸ì²œ": ["ê°•í™”êµ°", "ì˜¹ì§„êµ°", "ì¤‘êµ¬", "ë™êµ¬", "ë¯¸ì¶”í™€êµ¬", "ì—°ìˆ˜êµ¬", "ë‚¨ë™êµ¬",
             "ë¶€í‰êµ¬", "ê³„ì–‘êµ¬", "ì„œêµ¬"],
    "ê´‘ì£¼": ["ë™êµ¬", "ì„œêµ¬", "ë‚¨êµ¬", "ë¶êµ¬", "ê´‘ì‚°êµ¬"],
    "ëŒ€ì „": ["ë™êµ¬", "ì¤‘êµ¬", "ì„œêµ¬", "ìœ ì„±êµ¬", "ëŒ€ë•êµ¬"],
    "ìš¸ì‚°": ["ì¤‘êµ¬", "ë‚¨êµ¬", "ë™êµ¬", "ë¶êµ¬", "ìš¸ì£¼êµ°"],
    "ì„¸ì¢…": [],
    "ê²½ê¸°": ["ìˆ˜ì›ì‹œ", "ê³ ì–‘ì‹œ", "ìš©ì¸ì‹œ", "ì„±ë‚¨ì‹œ", "ë¶€ì²œì‹œ", "í™”ì„±ì‹œ", "ì•ˆì‚°ì‹œ",
             "ë‚¨ì–‘ì£¼ì‹œ", "ì•ˆì–‘ì‹œ", "í‰íƒì‹œ", "ì‹œí¥ì‹œ", "íŒŒì£¼ì‹œ", "ì˜ì •ë¶€ì‹œ",
             "ê¹€í¬ì‹œ", "ê´‘ì£¼ì‹œ", "ê´‘ëª…ì‹œ", "êµ°í¬ì‹œ", "í•˜ë‚¨ì‹œ", "ì˜¤ì‚°ì‹œ", "ì–‘ì£¼ì‹œ",
             "ì´ì²œì‹œ", "êµ¬ë¦¬ì‹œ", "ì•ˆì„±ì‹œ", "í¬ì²œì‹œ", "ì˜ì™•ì‹œ", "ì–‘í‰êµ°", "ì—¬ì£¼ì‹œ",
             "ë™ë‘ì²œì‹œ", "ê³¼ì²œì‹œ", "ê°€í‰êµ°", "ì—°ì²œêµ°"],
    "ê°•ì›": ["ì¶˜ì²œì‹œ", "ì›ì£¼ì‹œ", "ê°•ë¦‰ì‹œ", "ë™í•´ì‹œ", "íƒœë°±ì‹œ", "ì†ì´ˆì‹œ", "ì‚¼ì²™ì‹œ",
             "í™ì²œêµ°", "íš¡ì„±êµ°", "ì˜ì›”êµ°", "í‰ì°½êµ°", "ì •ì„ êµ°", "ì² ì›êµ°", "í™”ì²œêµ°",
             "ì–‘êµ¬êµ°", "ì¸ì œêµ°", "ê³ ì„±êµ°", "ì–‘ì–‘êµ°"],
    "ì¶©ë¶": ["ì²­ì£¼ì‹œ", "ì¶©ì£¼ì‹œ", "ì œì²œì‹œ", "ë³´ì€êµ°", "ì˜¥ì²œêµ°", "ì˜ë™êµ°", "ì¦í‰êµ°",
             "ì§„ì²œêµ°", "ê´´ì‚°êµ°", "ìŒì„±êµ°", "ë‹¨ì–‘êµ°"],
    "ì¶©ë‚¨": ["ì²œì•ˆì‹œ", "ê³µì£¼ì‹œ", "ë³´ë ¹ì‹œ", "ì•„ì‚°ì‹œ", "ì„œì‚°ì‹œ", "ë…¼ì‚°ì‹œ", "ê³„ë£¡ì‹œ",
             "ë‹¹ì§„ì‹œ", "ê¸ˆì‚°êµ°", "ë¶€ì—¬êµ°", "ì„œì²œêµ°", "ì²­ì–‘êµ°", "í™ì„±êµ°", "ì˜ˆì‚°êµ°",
             "íƒœì•ˆêµ°"],
    "ì „ë¶": ["ì „ì£¼ì‹œ", "êµ°ì‚°ì‹œ", "ìµì‚°ì‹œ", "ì •ìì‹œ", "ë‚¨ì›ì‹œ", "ê¹€ì œì‹œ", "ì™„ì£¼êµ°",
             "ì§„ì•ˆêµ°", "ë¬´ì£¼êµ°", "ì¥ìˆ˜êµ°", "ì„ì‹¤êµ°", "ìˆœì°½êµ°", "ê³ ì°½êµ°", "ë¶€ì•ˆêµ°"],
    "ì „ë‚¨": ["ëª©í¬ì‹œ", "ì—¬ìˆ˜ì‹œ", "ìˆœì²œì‹œ", "ë‚˜ì£¼ì‹œ", "ê´‘ì–‘ì‹œ", "ë‹´ì–‘êµ°", "ê³¡ì„±êµ°",
             "êµ¬ë¡€êµ°", "ê³ í¥êµ°", "ë³´ì„±êµ°", "í™”ìˆœêµ°", "ì¥í¥êµ°", "ê°•ì§„êµ°", "í•´ë‚¨êµ°",
             "ì˜ì•”êµ°", "ë¬´ì•ˆêµ°", "í•¨í‰êµ°", "ì˜ê´‘êµ°", "ì¥ì„±êµ°", "ì™„ë„êµ°", "ì§„ë„êµ°",
             "ì‹ ì•ˆêµ°"],
    "ê²½ë¶": ["í¬í•­ì‹œ", "ê²½ì£¼ì‹œ", "ê¹€ì²œì‹œ", "ì•ˆë™ì‹œ", "êµ¬ë¯¸ì‹œ", "ì˜ì£¼ì‹œ", "ì˜ì²œì‹œ",
             "ìƒì£¼ì‹œ", "ë¬¸ê²½ì‹œ", "ê²½ì‚°ì‹œ", "ì˜ì„±êµ°", "ì²­ì†¡êµ°", "ì˜ì–‘êµ°", "ì˜ë•êµ°",
             "ì²­ë„êµ°", "ê³ ë ¹êµ°", "ì„±ì£¼êµ°", "ì¹ ê³¡êµ°", "ì˜ˆì²œêµ°", "ë´‰í™”êµ°", "ìš¸ì§„êµ°",
             "ìš¸ë¦‰êµ°"],
    "ê²½ë‚¨": ["ì°½ì›ì‹œ", "ì§„ì£¼ì‹œ", "í†µì˜ì‹œ", "ì‚¬ì²œì‹œ", "ê¹€í•´ì‹œ", "ë°€ì–‘ì‹œ", "ê±°ì œì‹œ",
             "ì–‘ì‚°ì‹œ", "ì˜ë ¹êµ°", "í•¨ì•ˆêµ°", "ì°½ë…•êµ°", "ê³ ì„±êµ°", "ë‚¨í•´êµ°", "í•˜ë™êµ°",
             "ì‚°ì²­êµ°", "í•¨ì–‘êµ°", "ê±°ì°½êµ°", "í•©ì²œêµ°"],
    "ì œì£¼": ["ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ"]
}

############################
# 3) Streamlit ê¸°ë³¸ UI
############################
st.title("ğŸ’¬ ë§ì¶¤í˜• ì±„ìš© ê³µê³  ì¶”ì²œ ì„œë¹„ìŠ¤")
st.markdown("""
    <div style="height: 4px; background-color: #006400; margin-bottom: 20px;"></div>
""", unsafe_allow_html=True)
st.markdown("""
    <style>
        /* í…ìŠ¤íŠ¸ ì…ë ¥ì°½ (text_input, text_area) */
        textarea, input[type="text"] {
        background-color: #F8FFF8 !important;  /* ì—°í•œ ì´ˆë¡ ë°°ê²½ */
        color: #000000 !important;             /* í…ìŠ¤íŠ¸ ìƒ‰ */
        border: 2px solid #006400 !important;  /* ì§„í•œ ì´ˆë¡ í…Œë‘ë¦¬ */
        border-radius: 6px;
        padding: 10px;
        }
        /* ì œëª© ë° ì£¼ìš” í…ìŠ¤íŠ¸ì— ì§„í•œ ì´ˆë¡ìƒ‰ ê°•ì¡° */
        .main-title, h1, h2, h3, h4, h5, h6 {
            color: #006400;
        }
        /* ë©€í‹°ì…€ë ‰íŠ¸ ì „ì²´ ì…ë ¥ì°½ ì˜ì—­ */
        div[data-baseweb="select"] > div {
        background-color: #F8FFF8 !important;  /* í•˜ì–€ ë°°ê²½ */
        border: 2px solid #006400 !important;  /* ì§„í•œ ì´ˆë¡ í…Œë‘ë¦¬ */
        border-radius: 8px !important;
        }
        /* ë²„íŠ¼ê³¼ ë§í¬ì— ì§„í•œ ì´ˆë¡ìƒ‰ ì ìš© */
        .stButton button, a {
            background-color: #006400;
            color: #FFFFFF;
            border: none;
        }
        .stButton button:hover, a:hover {
            background-color: #004d00;
        }
    </style>
""", unsafe_allow_html=True)

############################
# 'ë§ì¶¤í˜• ì±„ìš© ê³µê³  ì¶”ì²œ' UI
############################
if st.session_state["selected_tab"] == "job_recommendation":
    st.subheader("ğŸ‘ ì§€ì›ìë‹˜ì˜ ìš”ì²­ ì‚¬í•­ì— ë§ëŠ” ê³µê³ ë“¤ì„ ì¶”ì²œí•´ë“œë ¤ìš”.")
    st.subheader("""
    ğŸ“Œ **ì…ë ¥ ì‹œ ì•ˆë‚´ì‚¬í•­**

    ì…ë ¥í•˜ì‹¤ ë•Œ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ëª¨í˜¸í•œ ë¶€ë¶„ì´ ìˆì–´ë„ ê±±ì •í•˜ì§€ ë§ˆì„¸ìš”!  
    í•´ë‹¹ ë‚´ìš©ì€ ìƒëµí•˜ì…”ë„ ê´œì°®ìœ¼ë©°, ì œê³µí•´ì£¼ì‹  ì •ë³´ë§Œìœ¼ë¡œë„ ìµœì ì˜ ì±„ìš© ê³µê³ ë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”.
    """)

    # (1) ì§€ì› ì§ë¬´(ê³µê³ ì œëª©)
    job_title = st.text_input("1ï¸âƒ£ ì§€ì›í•˜ê³ ì í•˜ëŠ” **ì§ë¬´ëª…**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ë°ì´í„° ë¶„ì„ê°€")

    # (2) ê²½ë ¥
    experience = st.slider("2ï¸âƒ£ ì§€ì›í•˜ê³ ì í•˜ëŠ” ë¶„ì•¼ì™€ ê´€ë ¨ëœ **ê²½ë ¥**(ê·¼ë¬´ ì—°ìˆ˜)ì„ ì„ íƒí•´ì£¼ì„¸ìš”.", 0, 20, 0)

    # (3) ê·¼ë¬´ ì‹œ/ë„ ì„ íƒ
    if st.session_state["selected_sido"] == ["ì „ì²´"]:
        sido_options = ["ì „ì²´"]
        default_vals = ["ì „ì²´"]
    else:
        sido_options = ["ì „ì²´"] + list(location_dict.keys())
        default_vals = st.session_state["selected_sido"]

    def update_sido_selection():
        current_sido = st.session_state["selected_sido_widget"]
        if "ì „ì²´" in current_sido:
            st.session_state["selected_sido"] = ["ì „ì²´"]
        else:
            st.session_state["selected_sido"] = [s for s in current_sido if s in location_dict]

    st.multiselect(
        "3ï¸âƒ£ ì›í•˜ì‹œëŠ” **ê·¼ë¬´ ìœ„ì¹˜**(ì‹œ/ë„)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
        options=sido_options,
        default=default_vals,
        key="selected_sido_widget",
        on_change=update_sido_selection
    )

    # (4) ì‹œ/êµ°/êµ¬ ì„ íƒ
    selected_sigungu = []
    if st.session_state["selected_sido"] == ["ì „ì²´"]:
        for sido_key, sigungu_list in location_dict.items():
            if sido_key == "ì„¸ì¢…":
                selected_sigungu.append("ì„¸ì¢…")
            else:
                for sg in sigungu_list:
                    selected_sigungu.append(f"{sido_key} {sg}")
    else:
        for sido in st.session_state["selected_sido"]:
            if sido == "ì„¸ì¢…":
                selected_sigungu.append("ì„¸ì¢…")
                continue

            sigungu_key = f"selected_sigungu_{sido}"
            widget_key = f"{sigungu_key}_widget"

            if sigungu_key not in st.session_state:
                st.session_state[sigungu_key] = []

            def make_sigungu_callback(sido_=sido):
                def _cb():
                    current_ = st.session_state[widget_key]
                    if "ì „ì²´" in current_:
                        st.session_state[sigungu_key] = ["ì „ì²´"]
                    else:
                        st.session_state[sigungu_key] = [
                            sg for sg in current_ if sg in location_dict[sido_]
                        ]
                return _cb

            if st.session_state[sigungu_key] == ["ì „ì²´"]:
                this_options = ["ì „ì²´"]
                this_defaults = ["ì „ì²´"]
            else:
                this_options = ["ì „ì²´"] + location_dict[sido]
                this_defaults = st.session_state[sigungu_key]

            st.multiselect(
                f"ğŸ“ {sido}ì˜ ì‹œ/êµ°/êµ¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                options=this_options,
                default=this_defaults,
                key=widget_key,
                on_change=make_sigungu_callback(sido)
            )

        for sido in st.session_state["selected_sido"]:
            if sido == "ì„¸ì¢…":
                continue
            sigungu_key = f"selected_sigungu_{sido}"
            if sigungu_key not in st.session_state:
                continue

            if st.session_state[sigungu_key] == ["ì „ì²´"]:
                for sg in location_dict[sido]:
                    selected_sigungu.append(f"{sido} {sg}")
            else:
                for sg in st.session_state[sigungu_key]:
                    selected_sigungu.append(f"{sido} {sg}")

    # (5) ì›í•˜ëŠ” ì—…ë¬´(ì£¼ìš”ì—…ë¬´)
    job_task = st.text_area("4ï¸âƒ£ ì›í•˜ì‹œëŠ” **ì—…ë¬´**ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ì €ëŠ” ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”ë¥¼ í•˜ê³  ì‹¶ì–´ìš”.")
    job_task_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_task_importance") if job_task else None
    )

    # (6) ë³¸ì¸ì˜ ìŠ¤í‚¬ ë° í™œìš© ê°€ëŠ¥í•œ íˆ´ (ìê²©ìš”ê±´ ë° ìš°ëŒ€ì‚¬í•­)
    job_skills = st.text_area("5ï¸âƒ£ ì§€ì›ìë‹˜ì˜ **ìŠ¤í‚¬ ë° í™œìš© ê°€ëŠ¥í•œ íˆ´**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) Pythonê³¼ SQLì„ ì˜í•´ìš”.")
    job_skills_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_skills_importance") if job_skills else None
    )

    # (7) ì›í•˜ì‹œëŠ” í˜œíƒ ë° ë³µì§€
    job_benefits = st.text_area("6ï¸âƒ£ ì›í•˜ì‹œëŠ” **í˜œíƒ ë° ë³µì§€**ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.", placeholder="ì˜ˆ) ìœ ì—°ê·¼ë¬´ê°€ ê°€ëŠ¥í–ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”.")
    job_benefits_importance = (
        st.slider("â­ï¸ ì¤‘ìš”ë„", 1, 5, 3, key="job_benefits_importance") if job_benefits else None
    )
    
    if "analysis_result" not in st.session_state:
        st.session_state["analysis_result"] = None
    if "submitted" not in st.session_state:
        st.session_state["submitted"] = False

    # (A) submitted=False â†’ í™œì„± ë²„íŠ¼
    if not st.session_state["submitted"]:
        if st.button("ğŸš€ ë‹µë³€ ì œì¶œ"):
            st.session_state["submitted"] = True
            st.rerun()

    # (B) submitted=True â†’ ë¹„í™œì„±í™” ë²„íŠ¼ & ë¶„ì„ ìˆ˜í–‰
    if st.session_state["submitted"]:
        with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.ï¸"):
            ##############################################################################
            # A) ì‚¬ìš©ì ì…ë ¥ êµ¬ì¡°í™”: ê²½ë ¥, ê·¼ë¬´ìœ„ì¹˜ => í•˜ë“œí•„í„°
            #    (ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€) => ì†Œí”„íŠ¸í•„í„°
            #    (ê³µê³ ì œëª©) => ë³„ë„ ë¡œì§
            ##############################################################################
            hard_filter_dict = {
                "ê²½ë ¥": experience,
                "ê·¼ë¬´ìœ„ì¹˜": selected_sigungu
            }

            # ì†Œí”„íŠ¸í•„í„°(ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€)ë§Œ dictì— ë‹´ìŒ
            soft_filters = []
            if job_task and job_task_importance is not None:
                soft_filters.append(("ì£¼ìš”ì—…ë¬´", [job_task.strip()], job_task_importance))
            if job_skills and job_skills_importance is not None:
                # "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" ì»¬ëŸ¼ì— ë§¤ì¹­
                soft_filters.append(("ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­", [job_skills.strip()], job_skills_importance))
            if job_benefits and job_benefits_importance is not None:
                soft_filters.append(("í˜œíƒë°ë³µì§€", [job_benefits.strip()], job_benefits_importance))

            total_importance = sum([f[2] for f in soft_filters])
            soft_filter_dict = {}
            if total_importance > 0:
                for col_name, kw_list, imp in soft_filters:
                    weight = round(imp / total_importance, 4)
                    soft_filter_dict[col_name] = {
                        "ê°€ì¤‘ì¹˜": weight,
                        "ì¡°ê±´": kw_list
                    }

            user_input_json = {"soft_filter": soft_filter_dict}
            job_title_input = job_title.strip()

            ##############################################################################
            # B) ì„ë² ë”© ëª¨ë¸ ë° ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ (BGEë§Œ ì‚¬ìš©)
            ##############################################################################
            db_path = "./chroma_db_bge"
            bge_model = get_bge_model()  # @st.cache_resource(show_spinner=False)ë¡œ ìºì‹±ëœ BGE ëª¨ë¸

            def embed_with_model(text: str):
                if not text.strip():
                    text = " "
                out = bge_model.encode(
                    [text],
                    max_length=1024,
                    return_dense=True,
                    return_sparse=False,
                    return_colbert_vecs=False
                )
                return out["dense_vecs"][0]

            collection = get_chroma_collection(db_path, "job_postings_collection")

            def cosine_similarity(vec1, vec2):
                dot = np.dot(vec1, vec2)
                norm1 = np.linalg.norm(vec1)
                norm2 = np.linalg.norm(vec2)
                if norm1 == 0 or norm2 == 0:
                    return 0.0
                return float(dot / (norm1 * norm2))

            ##############################################################################
            # C) í•˜ë“œí•„í„° (ê²½ë ¥, ê·¼ë¬´ìœ„ì¹˜) -> ChromaDB Where ì¡°ê±´
            ##############################################################################
            hard_exp = float(hard_filter_dict["ê²½ë ¥"])
            hard_locs = hard_filter_dict["ê·¼ë¬´ìœ„ì¹˜"]

            and_conditions = []
            # (1) ê²½ë ¥ ì¡°ê±´
            and_conditions.append({"ê²½ë ¥": {"$lte": hard_exp}})

            # (2) ê·¼ë¬´ìœ„ì¹˜ ì¡°ê±´
            if "ì „ì²´" not in hard_locs and len(hard_locs) > 0:
                and_conditions.append({"ê·¼ë¬´ìœ„ì¹˜": {"$in": hard_locs}})

            if len(and_conditions) == 1:
                where_clause = and_conditions[0]
            elif len(and_conditions) > 1:
                where_clause = {"$and": and_conditions}
            else:
                where_clause = {}

            filtered_docs = collection.get(
                where=where_clause,
                include=["embeddings", "metadatas"],
                limit=999999
            )

            if len(filtered_docs["ids"]) == 0:
                st.warning("ê²½ë ¥ ë° ê·¼ë¬´ìœ„ì¹˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ê³µê³ ê°€ ì—†ì–´ìš”.")
                st.stop()

            ##############################################################################
            # D) ê³µê³ ì œëª© + ë‚˜ë¨¸ì§€ ì†Œí”„íŠ¸í•„í„° ë¡œì§ ë¶„ê¸°
            # - Case A: job_titleë§Œ ìˆê³  (job_task, job_skills, job_benefits)ëŠ” ì—†ìŒ
            # - Case B: job_title + (ì£¼ìš”ì—…ë¬´ or ìê²©ìš”ê±´ or í˜œíƒ) ì¤‘ í•˜ë‚˜ ì´ìƒ
            # - Case C: job_titleì´ ì—†ê³ , ì†Œí”„íŠ¸í•„í„°(ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´, í˜œíƒ) ìˆìŒ
            # - Case D: job_titleì´ ì—†ê³ , ì†Œí”„íŠ¸í•„í„°ë„ ì—†ìŒ
            ##############################################################################
            has_job_title = bool(job_title_input)
            has_job_task = bool(job_task.strip())
            has_job_skills = bool(job_skills.strip())
            has_job_benefits = bool(job_benefits.strip())
            soft_filter_count = sum([has_job_task, has_job_skills, has_job_benefits])

            # ================================
            # D-1) ìœ í‹¸: ìµœì¢… ê³µê³  í‘œì‹œ í•¨ìˆ˜
            # ================================
            def show_job_postings(final_df):
                for idx, (_, row) in enumerate(final_df.iterrows(), start=1):
                    st.markdown(f"### Top {idx}: {row['ê³µê³ ì œëª©']}")
                    st.markdown(f"**íšŒì‚¬ëª…:** {row['íšŒì‚¬ëª…']}")
                    display_partial_text("ì£¼ìš” ì—…ë¬´", row.get("ì£¼ìš”ì—…ë¬´", ""))
                    display_partial_text("ìê²© ìš”ê±´", row.get("ìê²©ìš”ê±´", ""))
                    display_partial_text("ìš°ëŒ€ ì‚¬í•­", row.get("ìš°ëŒ€ì‚¬í•­", ""))
                    display_partial_text("í˜œíƒ ë° ë³µì§€", row.get("í˜œíƒë°ë³µì§€", ""))
                    st.markdown(f"**ê·¼ë¬´ ìœ„ì¹˜:** {row.get('ê·¼ë¬´ìœ„ì¹˜','')}")
                    exp_val = row.get("ê²½ë ¥",0)
                    exp_str = "ì‹ ì…" if int(exp_val) == 0 else f"{int(exp_val)}ë…„ ì´ìƒ"
                    st.markdown(f"**ê²½ë ¥:** {exp_str}")
                    st.markdown(f"**ìµœì¢… ì ìˆ˜:** {row.get('ìµœì¢…ì ìˆ˜','0.0')}")
                    url_val = row.get("ê³µê³ ìƒì„¸url", "")
                    if pd.notna(url_val) and url_val:
                        st.markdown(f"""
                            <a href="{url_val}" target="_blank" style="
                                text-decoration: underline;
                                color: #006400;
                                background-color: transparent;
                                padding: 0;
                                font-weight: bold;
                            ">ğŸ”— ë°”ë¡œê°€ê¸°</a>
                        """, unsafe_allow_html=True)
                    st.markdown("""
                        <div style="height: 1px; background-color: #006400; margin-bottom: 20px;"></div>
                    """, unsafe_allow_html=True)

            # ==============================================
            # D-2) â€œì†Œí”„íŠ¸í•„í„°â€ (ì£¼ìš”ì—…ë¬´, ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­, í˜œíƒë°ë³µì§€) ê³„ì‚° í•¨ìˆ˜
            # ==============================================
            def calc_soft_filter_scores(docs, user_filter_dict):
                """
                docs: í•˜ë“œí•„í„°ë¥¼ í†µê³¼í•œ ChromaDB ë¬¸ì„œë“¤
                user_filter_dict: {"ì£¼ìš”ì—…ë¬´": {...}, "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­": {...}, "í˜œíƒë°ë³µì§€": {...}}
                """
                # 1) ê° í•„ë“œë³„ ì‚¬ìš©ì ì„ë² ë”©
                keyword_embeddings = {}
                for col_type, info in user_filter_dict.items():
                    emb_list = []
                    for kw in info["ì¡°ê±´"]:
                        emb_list.append(embed_with_model(kw))
                    keyword_embeddings[col_type] = emb_list

                # 2) job_idë³„ raw ìœ ì‚¬ë„
                sim_raw = {}
                for i, doc_id in enumerate(docs["ids"]):
                    emb = np.array(docs["embeddings"][i], dtype=np.float32)
                    meta = docs["metadatas"][i]
                    j_id = meta["ê³µê³ id"]
                    t = meta["type"]

                    if j_id not in sim_raw:
                        sim_raw[j_id] = {}

                    if t in user_filter_dict:
                        kw_embs = keyword_embeddings[t]
                        if len(kw_embs) == 0:
                            raw_sim = 0.0
                        else:
                            scores = []
                            for kw_vec in kw_embs:
                                s = cosine_similarity(emb, kw_vec)
                                scores.append(s)
                            raw_sim = np.mean(scores) if scores else 0.0

                        sim_raw[j_id][t] = raw_sim

                # 3) ìµœì¢… ì ìˆ˜ (ê°€ì¤‘í•©)
                final_scores = {}
                for j_id in sim_raw.keys():
                    score_sum = 0.0
                    for doc_type, info in user_filter_dict.items():
                        raw_val = sim_raw[j_id].get(doc_type, 0.0)
                        weight = info["ê°€ì¤‘ì¹˜"]
                        score_sum += raw_val * weight
                    final_scores[j_id] = score_sum

                return final_scores

            # ======================================================
            # D-3) í•˜ë“œí•„í„° í†µê³¼í•œ ë¬¸ì„œë“¤ ì¤‘ì—ì„œ job_id ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            # ======================================================
            all_job_ids = []
            for meta in filtered_docs["metadatas"]:
                j_id = meta["ê³µê³ id"]
                if j_id not in all_job_ids:
                    all_job_ids.append(j_id)

            # ======================================================
            # D-4) ìƒí™©ë³„ ë¶„ê¸°
            # ======================================================
            if has_job_title and soft_filter_count == 0:
                # --------------------------------------------------
                # Case A: ê³µê³ ì œëª© "ë‹¨ë…"
                # --------------------------------------------------
                title_vec = embed_with_model(job_title_input)

                doc_scores = {}
                for i, doc_id in enumerate(filtered_docs["ids"]):
                    meta = filtered_docs["metadatas"][i]
                    t = meta["type"]
                    j_id = meta["ê³µê³ id"]
                    if t == "ê³µê³ ì œëª©":
                        emb = np.array(filtered_docs["embeddings"][i], dtype=np.float32)
                        sim = cosine_similarity(title_vec, emb)
                        doc_scores[j_id] = sim

                if not doc_scores:
                    st.warning("ê³µê³ ì œëª© ì„ë² ë”©ì„ ê³„ì‚°í–ˆì§€ë§Œ, í•´ë‹¹ íƒ€ì… ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                sorted_ids = sorted(doc_scores.keys(), key=lambda x: doc_scores[x], reverse=True)[:5]

                # [ìºì‹±] ì—‘ì…€ íŒŒì¼ ë¡œë“œ
                df_all = load_all_excel_data("./all_raw.xlsx")
                top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
                top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(doc_scores.get(str(x), 0.0), 4))
                top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

                if len(top_df) == 0:
                    st.warning("ê³µê³ ì œëª© ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ ê²°ê³¼ê°€ ì—†ì–´ìš”.")
                    st.stop()

                st.success("ğŸ” ì‘ì„±í•˜ì‹  ì§ë¬´ ê¸°ë°˜ ìƒìœ„ 5ê°œ ê³µê³ ë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
                show_job_postings(top_df)

            elif has_job_title and soft_filter_count > 0:
                # --------------------------------------------------
                # Case B: ê³µê³ ì œëª© + (ì£¼ìš”ì—…ë¬´ or ìê²©ìš”ê±´ or í˜œíƒ ë“±) 1ê°œ ì´ìƒ
                # --------------------------------------------------
                title_vec = embed_with_model(job_title_input)

                pass_ids = []
                for i, doc_id in enumerate(filtered_docs["ids"]):
                    meta = filtered_docs["metadatas"][i]
                    t = meta["type"]
                    j_id = meta["ê³µê³ id"]
                    if t == "ê³µê³ ì œëª©":
                        emb = np.array(filtered_docs["embeddings"][i], dtype=np.float32)
                        sim = cosine_similarity(title_vec, emb)
                        # thresholdë¡œ 0.7
                        if sim >= 0.7:
                            if j_id not in pass_ids:
                                pass_ids.append(j_id)

                if not pass_ids:
                    st.warning("ì§ë¬´ ì¡°ê±´ì˜ thresholdë¥¼ ë§Œì¡±í•˜ëŠ” ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.stop()

                pass_docs_ids = []
                pass_docs_embeddings = []
                pass_docs_metas = []

                for i, doc_id in enumerate(filtered_docs["ids"]):
                    meta = filtered_docs["metadatas"][i]
                    j_id = meta["ê³µê³ id"]
                    if j_id in pass_ids:
                        pass_docs_ids.append(doc_id)
                        pass_docs_embeddings.append(filtered_docs["embeddings"][i])
                        pass_docs_metas.append(meta)

                pass_docs = {
                    "ids": pass_docs_ids,
                    "embeddings": pass_docs_embeddings,
                    "metadatas": pass_docs_metas
                }

                if len(soft_filter_dict) == 0:
                    # í˜¹ì‹œ ëª¨ë¥¼ ì¼€ì´ìŠ¤ ëŒ€ë¹„
                    job_ids = []
                    for meta in pass_docs["metadatas"]:
                        j_id = meta["ê³µê³ id"]
                        if j_id not in job_ids:
                            job_ids.append(j_id)
                    top5_ids = job_ids[:5]
                    df_all = load_all_excel_data("./all_raw.xlsx")
                    filtered_df = df_all[df_all["ê³µê³ id"].isin(top5_ids)].copy()
                    filtered_df["ìµœì¢…ì ìˆ˜"] = 0.0
                    show_job_postings(filtered_df)
                    st.stop()
                else:
                    final_scores = calc_soft_filter_scores(pass_docs, soft_filter_dict)
                    if not final_scores:
                        st.warning("ì†Œí”„íŠ¸í•„í„° ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë¬¸ì„œê°€ ì—†ì–´ìš”.")
                        st.stop()
                    sorted_ids = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:5]
                    if not sorted_ids:
                        st.warning("ì†Œí”„íŠ¸í•„í„°ë¥¼ ë§Œì¡±í•˜ëŠ” ìƒìœ„ ê³µê³ ê°€ ì—†ì–´ìš”.")
                        st.stop()

                    df_all = load_all_excel_data("./all_raw.xlsx")
                    top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
                    top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(final_scores.get(str(x), 0.0), 4))
                    top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

                    st.success("ğŸ” ë§ì¶¤í˜• ê³µê³  ìƒìœ„ 5ê°œë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
                    st.markdown("""
                                <div style="height: 4px; background-color: #006400; margin-bottom: 20px;"></div>""",
                                unsafe_allow_html=True
                    )
                    show_job_postings(top_df)

            else:
                # --------------------------------------------------
                # ê³µê³ ì œëª©ì´ ì—†ëŠ” ê²½ìš° -> Case C, D
                # --------------------------------------------------
                if len(soft_filter_dict) == 0:
                    # Case D: ì†Œí”„íŠ¸í•„í„° ì „ë¬´
                    job_ids = []
                    for meta in filtered_docs["metadatas"]:
                        j_id = meta["ê³µê³ id"]
                        if j_id not in job_ids:
                            job_ids.append(j_id)
                    top5 = job_ids[:5]

                    df_all = load_all_excel_data("./all_raw.xlsx")
                    filtered_df = df_all[df_all["ê³µê³ id"].isin(top5)].copy()
                    filtered_df["ìµœì¢…ì ìˆ˜"] = 0.0
                    show_job_postings(filtered_df)
                else:
                    # Case C: ê³µê³ ì œëª©ì€ ì—†ê³ , ì†Œí”„íŠ¸í•„í„° ì¡´ì¬
                    final_scores = calc_soft_filter_scores(filtered_docs, soft_filter_dict)
                    if not final_scores:
                        st.warning("ì†Œí”„íŠ¸í•„í„° ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë¬¸ì„œê°€ ì—†ì–´ìš”.")
                        st.stop()
                    sorted_ids = sorted(final_scores.keys(), key=lambda x: final_scores[x], reverse=True)[:5]
                    if not sorted_ids:
                        st.warning("ì†Œí”„íŠ¸í•„í„° ê²°ê³¼, ìƒìœ„ ê³µê³ ê°€ ì—†ì–´ìš”.")
                        st.stop()

                    df_all = load_all_excel_data("./all_raw.xlsx")
                    top_df = df_all[df_all["ê³µê³ id"].isin(sorted_ids)].copy()
                    top_df["ìµœì¢…ì ìˆ˜"] = top_df["ê³µê³ id"].apply(lambda x: round(final_scores.get(str(x), 0.0), 4))
                    top_df = top_df.sort_values("ìµœì¢…ì ìˆ˜", ascending=False)

                    st.success("ğŸ” ë§ì¶¤í˜• ê³µê³  ìƒìœ„ 5ê°œë¥¼ ë³´ì—¬ë“œë ¤ìš”!")
                    st.markdown("""
                                <div style="height: 4px; background-color: #006400; margin-bottom: 20px;"></div>
                                """, unsafe_allow_html=True)
                    show_job_postings(top_df)

            ######################################################
            # ì¶”ê°€: ì¶”ì²œ ì‚¬ìœ ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ ì •ì˜ (ê³µê³ ì œëª©ì€ ì œì™¸)
            ######################################################
            def generate_recommendation_rationale(user_input_json, top_df):
                provided_fields = [key for key in user_input_json["soft_filter"].keys()]
            
                # í”„ë¡¬í”„íŠ¸ ì´ˆê¸° êµ¬ì„±
                prompt = "ì•„ë˜ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†Œí”„íŠ¸ í•„í„° ì •ë³´ì™€ ì¶”ì²œëœ Top 5 ê³µê³ ì˜ ì£¼ìš” ë‚´ìš©ì…ë‹ˆë‹¤.\n\n"
            
                # ì‚¬ìš©ì ì…ë ¥ (ì†Œí”„íŠ¸ í•„í„°)
                prompt += "ì‚¬ìš©ì ì…ë ¥ (ì†Œí”„íŠ¸ í•„í„°):\n"
                for key in provided_fields:
                    if key == "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­":
                        prompt += f"- ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­ (ìê²©ìš”ê±´ ë° ìš°ëŒ€ì‚¬í•­ ëª¨ë‘ í•´ë‹¹): {user_input_json['soft_filter'][key]['ì¡°ê±´']}\n"
                    else:
                        prompt += f"- {key}: {user_input_json['soft_filter'][key]['ì¡°ê±´']}\n"
            
                # ì¶”ì²œëœ ì±„ìš© ê³µê³  ë‚´ìš© - Top ìˆœì„œëŒ€ë¡œ
                prompt += "\nì¶”ì²œëœ ì±„ìš© ê³µê³  ë‚´ìš©:\n"
                for i, (_, row) in enumerate(top_df.iterrows(), start=1):
                    prompt += f"Top {i}: **{row['ê³µê³ ì œëª©']}**\n"
                    if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                        prompt += f"  - **ì£¼ìš”ì—…ë¬´:** {row['ì£¼ìš”ì—…ë¬´']}\n\n"
                    if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                        prompt += f"  - **ìê²©ìš”ê±´:** {row.get('ìê²©ìš”ê±´', '')}\n\n"
                        prompt += f"  - **ìš°ëŒ€ì‚¬í•­:** {row.get('ìš°ëŒ€ì‚¬í•­', '')}\n\n"
                    if "í˜œíƒë°ë³µì§€" in provided_fields:
                        prompt += f"  - **í˜œíƒë°ë³µì§€:** {row['í˜œíƒë°ë³µì§€']}\n\n"
                    prompt += "\n---\n\n"
            
                # ì‚¬ìš©ìê°€ ì…ë ¥í•œ í•„ë“œë§Œ ì„¤ëª…í•˜ë„ë¡ ìš”ì²­
                fields_explanation = []
                if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                    fields_explanation.append("ì£¼ìš”ì—…ë¬´")
                if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                    fields_explanation.append("ìê²©ìš”ê±´")
                    fields_explanation.append("ìš°ëŒ€ì‚¬í•­")
                if "í˜œíƒë°ë³µì§€" in provided_fields:
                    fields_explanation.append("í˜œíƒë°ë³µì§€")
                fields_text = ", ".join(fields_explanation)
            
                prompt += (
                    "ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, ê° ì¶”ì²œ ê³µê³ ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†Œí”„íŠ¸ í•„í„° í•­ëª© ì¤‘ "
                    f"[{fields_text}]ì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì´ ê³µê³  ë‚´ìš©ì—ì„œ ì–´ë–»ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n\n"
                    "í˜•ì‹ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹):\n"
                    "ğŸ”·**Top 1: [ê³µê³ ì œëª©]**\n\n"
                )
                if "ì£¼ìš”ì—…ë¬´" in provided_fields:
                    prompt += " â–ªï¸ **ì£¼ìš”ì—…ë¬´:** <ì„¤ëª…>\n\n"
                if "ìê²©ìš”ê±´ë°ìš°ëŒ€ì‚¬í•­" in provided_fields:
                    prompt += " â–ªï¸ **ìê²©ìš”ê±´:** <ì„¤ëª…>\n\n"
                    prompt += " â–ªï¸ **ìš°ëŒ€ì‚¬í•­:** <ì„¤ëª…>\n\n"
                if "í˜œíƒë°ë³µì§€" in provided_fields:
                    prompt += " â–ªï¸ **í˜œíƒë°ë³µì§€:** <ì„¤ëª…>\n\n"
            
                prompt += (
                    "ë‹¨, ì‚¬ìš©ìê°€ ì…ë ¥í•˜ì§€ ì•Šì€ í•­ëª©ì€ ì•„ì˜ˆ ì„¤ëª…ì—ì„œ ìƒëµí•´ ì£¼ì„¸ìš”. "
                    "ë˜í•œ, í•´ë‹¹ í•­ëª©ì´ ê³µê³  ë‚´ìš©ì—ì„œ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ” ê²½ìš°, 'í•´ë‹¹ í•­ëª©ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ëª…í™•í•˜ê²Œ ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'ë¼ê³  ê°„ë‹¨í•˜ê²Œ ì–¸ê¸‰í•´ ì£¼ì„¸ìš”.\n\n"
                    "**ì¤‘ìš”**: Top 1ë¶€í„° Top 5ê¹Œì§€ë¥¼ ì ˆëŒ€ë¡œ ìƒëµí•˜ì§€ ë§ê³  ì „ë¶€ ë³„ë„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”. "
                    "'ì´í•˜ ìƒëµ', '...' ë“±ì˜ ìš”ì•½ í‘œí˜„ ì—†ì´, ê° ê³µê³ ë¥¼ ëª¨ë‘ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                    "ë‹µë³€ì„ ìƒì„± ì‹œ 'ì‚¬ìš©ìê°€~'ë¼ëŠ” í‘œí˜„ ë§ê³  'ì§€ì›ìë‹˜ê»˜ì„œ~'ì™€ ê°™ì´ ë†’ì„ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼í•©ë‹ˆë‹¤. "
                )
            
                try:
                    response = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {
                                "role": "system",
                                "content": (
                                    "You are an assistant who explains job recommendation rationale based on user input "
                                    "and job posting data in markdown format. Do not fabricate explanations if the user's input "
                                    "is not clearly supported by the job posting content."
                                )
                            },
                            {"role": "user", "content": prompt},
                        ],
                        temperature=0.5
                    )
                    explanation = response.choices[0].message.content
                except Exception as e:
                    explanation = f"ì¶”ì²œ ì‚¬ìœ ë¥¼ ìƒì„±í•˜ëŠ” ë° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}"
            
                return explanation
            
            ######################################################
            # ì¶”ê°€: ë¡œë”© ë©”ì‹œì§€ì™€ í•¨ê»˜ ì¶”ì²œ ì‚¬ìœ  ìƒì„± ë° ì¶œë ¥
            ######################################################
            loading_msg = st.empty()
            loading_msg.markdown("#### â³ê³µê³  ì¶”ì²œ ì´ìœ ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”ï¸âŒ›")

            # top_dfëŠ” ê° ì¼€ì´ìŠ¤ ë¶„ê¸°(Case A/B/C/D)ì—ì„œ ìµœì¢…ì ìœ¼ë¡œ ì •ì˜ë¨
            explanation = generate_recommendation_rationale(user_input_json, top_df)
            if "latest_explanation" not in st.session_state:
                st.session_state["latest_explanation"] = []
            st.session_state["latest_explanation"] = explanation

        # ê²°ê³¼ ì €ì¥ í›„ ìƒíƒœ ë³µì›
        st.session_state["analysis_result"] = top_df
        st.session_state["submitted"] = False
        st.rerun()

    # (C) ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    if st.session_state["analysis_result"] is not None:
        st.success("ğŸ” ë§ì¶¤í˜• ê³µê³  ìƒìœ„ ê²°ê³¼ë¥¼ ë³´ì—¬ë“œë¦´ê²Œìš”!")
        df_result = st.session_state["analysis_result"]

        if df_result is not None and not df_result.empty:
            # ê°€ë¡œ ì¤„
            st.markdown("""<div style="height: 4px; background-color: #006400; margin-bottom: 20px;"></div>""", unsafe_allow_html=True)

            # DataFrame ìˆœíšŒí•˜ë©° ê¸°ì¡´ ë””ìì¸ëŒ€ë¡œ ì¶œë ¥
            for i, (df_index, row) in enumerate(df_result.iterrows(), start=1):
                st.markdown(f"### Top {i}: {row['ê³µê³ ì œëª©']}")
                st.markdown(f"**íšŒì‚¬ëª…:** {row['íšŒì‚¬ëª…']}")
                display_partial_text("ì£¼ìš” ì—…ë¬´", row.get("ì£¼ìš”ì—…ë¬´", ""))
                display_partial_text("ìê²© ìš”ê±´", row.get("ìê²©ìš”ê±´", ""))
                display_partial_text("ìš°ëŒ€ ì‚¬í•­", row.get("ìš°ëŒ€ì‚¬í•­", ""))
                display_partial_text("í˜œíƒ ë° ë³µì§€", row.get("í˜œíƒë°ë³µì§€", ""))
                st.markdown(f"**ê·¼ë¬´ ìœ„ì¹˜:** {row.get('ê·¼ë¬´ìœ„ì¹˜','')}")

                exp_val = row.get("ê²½ë ¥",0)
                exp_str = "ì‹ ì…" if int(exp_val) == 0 else f"{int(exp_val)}ë…„ ì´ìƒ"
                st.markdown(f"**ê²½ë ¥:** {exp_str}")

                st.markdown(f"**ìµœì¢… ì ìˆ˜:** {row.get('ìµœì¢…ì ìˆ˜', '0.0')}")

                url_val = row.get("ê³µê³ ìƒì„¸url", "")
                if pd.notna(url_val) and url_val:
                    st.markdown(f"""
                        <a href="{url_val}" target="_blank" style="
                            text-decoration: underline;
                            color: #006400;
                            background-color: transparent;
                            padding: 0;
                            font-weight: bold;
                        ">ğŸ”— ë°”ë¡œê°€ê¸°</a>
                    """, unsafe_allow_html=True)

                st.markdown("""
    <div style="height: 2px; background-color: #006400; margin-bottom: 20px;"></div>
""", unsafe_allow_html=True)
                
            st.markdown("---")
            if st.session_state["latest_explanation"] is not None:
                st.markdown("### ê³µê³  ì¶”ì²œ ì´ìœ ")
                st.write(st.session_state["latest_explanation"])
